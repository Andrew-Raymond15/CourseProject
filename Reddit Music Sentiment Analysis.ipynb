{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install praw emoji wordcloud --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en\n",
    "from IPython import display\n",
    "import math\n",
    "import praw\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "import spacy\n",
    "import sys\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "##########################\n",
    "#IMPORTANT \n",
    "#ENTER REDDIT LOGIN INFO HERE\n",
    "#PLEASE SEE LINK IN READ.ME FOR HOW TO SET THIS UP\n",
    "##########################\n",
    "\n",
    "\n",
    "Reddit_Login = praw.Reddit(\n",
    "    client_id=\"\",\n",
    "    client_secret=\"\",\n",
    "    user_agent=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69660e",
   "metadata": {},
   "source": [
    "Welcome to the Reddit Music Senitiment Analyzer\n",
    "\n",
    "Lets first start off with installing some required packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c81cf1",
   "metadata": {},
   "source": [
    "Now that we've installed our packages and entered out reddit app information lets choose and artist or a song!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cee3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CHOOSE ARTIST HERE\n",
    "\n",
    "Page = Reddit_Login.subreddit(\"Music\")\n",
    "\n",
    "Artist_or_Song = \"Queen\" #<----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = []\n",
    "for post in Page.search(Artist_or_Song, limit=5):\n",
    "    all_posts.append(post.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed448d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = []\n",
    "for post in all_posts:\n",
    "    sub = Reddit_Login.submission(id=post)\n",
    "    sub.comments.replace_more(limit=0)\n",
    "    for comments in sub.comments.list():\n",
    "        all_comments.append(comments.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a0774",
   "metadata": {},
   "source": [
    "In this cell we will clean the comments, remove stop words and emojis and lemmatize the words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85648c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string = all_comments\n",
    "string = [str(i) for i in string]\n",
    "string1 = ' , '.join(string)\n",
    "\n",
    "emoji_list = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "        u\"\\U00002500-\\U00002BEF\" \n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  \n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "\n",
    "string1_emojiless = emoji_list.sub(r'', string1)\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|http\\S+')\n",
    "\n",
    "string_tokens = tokenizer.tokenize(string1_emojiless)\n",
    "\n",
    "lowercase_tokens = []\n",
    "for word in string_tokens:\n",
    "    lowercase_tokens.append(word.lower())\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "words = lowercase_tokens\n",
    "tokens_no_sw = [word for word in words if not word in stopwords]\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lem_tokens = ([lemmatizer.lemmatize(w) for w in tokens_no_sw])\n",
    "\n",
    "string_clean = lem_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d24cf",
   "metadata": {},
   "source": [
    "In this cell we will run the VADER sentiment analysis on the comments gained from the reddit comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a2e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiment_analysis = SentimentIntensityAnalyzer()\n",
    "sentimentized = []\n",
    "\n",
    "for string in string_clean:\n",
    "    polarity_score = sentiment_analysis.polarity_scores(string)\n",
    "    polarity_score['words'] = string\n",
    "    sentimentized.append(polarity_score)\n",
    "\n",
    "pd.set_option('display.max_columns', None, 'max_colwidth', None)\n",
    "df = pd.DataFrame.from_records(sentimentized)\n",
    "df['label'] = 0\n",
    "df.loc[df['compound'] > 0.10, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.10, 'label'] = -1\n",
    "viz = df.loc[df['label'] != 0]\n",
    "viz.head()\n",
    "pos_word = list(df.loc[df['label'] == 1].words)\n",
    "neg_word = list(df.loc[df['label'] == -1].words)\n",
    "\n",
    "word_dist = list(df.loc[df['label'] != 0].words)\n",
    "\n",
    "print(viz.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0c4ee",
   "metadata": {},
   "source": [
    "Heres where we will see our results, We will produce a wordcloud of the most common words and we will show wether the comments are skewed towards negative or positive\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720ef8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words1 = [str(w)for w in pos_word]\n",
    "words2 = ' , '.join(words1)\n",
    "wordcloud = WordCloud(background_color='white',stopwords = STOPWORDS).generate(words2)\n",
    "\n",
    "words3 = [str(w)for w in neg_word]\n",
    "words4 = ' , '.join(words3)\n",
    "wordcloud2 = WordCloud(background_color='white',stopwords = STOPWORDS).generate(words4)\n",
    "\n",
    "words5 = [str(w)for w in string_clean]\n",
    "words6 = ' , '.join(words5)\n",
    "wordcloud3 = WordCloud(background_color='white',stopwords = STOPWORDS).generate(words6)\n",
    "\n",
    "bc = viz.label.value_counts(normalize = True)*100\n",
    "\n",
    "chart = sns.barplot(x = bc.index, y = bc)\n",
    "chart.set_xticklabels(['Neg','Pos'])\n",
    "chart.set_ylabel('Percent')\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud3, interpolation = 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005fd00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud2, interpolation = 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44484c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
